{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\14437\\AppData\\Local\\Temp\\ipykernel_17760\\4194378923.py:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  train_data = TabularDataset('C:\\\\code\\\\EL\\data\\\\train1.csv')\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "train_data = TabularDataset('C:\\\\code\\\\EL\\data\\\\train1.csv')\n",
    "label = 'MESFOC_nmile'\n",
    "time_limit=60*60\n",
    "save_path='C:\\\\code\\\\EL\\\\output'\n",
    "metric='r2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"C:\\code\\EL\\output\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.12.7\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          14\n",
      "Memory Avail:       20.61 GB / 31.43 GB (65.6%)\n",
      "Disk Space Avail:   799.16 GB / 952.49 GB (83.9%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"C:\\code\\EL\\output\"\n",
      "Train Data Rows:    224512\n",
      "Train Data Columns: 45\n",
      "Label Column:       MESFOC_nmile\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (4121.3896484375, -3972.890625, 36.6287, 58.50733)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21148.38 MB\n",
      "\tTrain Data (Original)  Memory Usage: 119.21 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['MEActMGOCons', 'BlrActMGOCons', 'BlrAccMGOCons']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 2): ['BlrFODensity', 'BlrMGODensity']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 2 | ['BlrFODensity', 'BlrMGODensity']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 31 | ['MEActFOCons', 'DGActFOCons', 'BlrActFOCons', 'DGActMGOCons', 'MEAccFOCons', ...]\n",
      "\t\t('int', [])                        :  5 | ['LogIndex', 'MERpm', 'METorque', 'MEShaftPow', 'WindDir']\n",
      "\t\t('object', [])                     :  2 | ['Latitude', 'Longitude']\n",
      "\t\t('object', ['datetime_as_object']) :  2 | ['PCDate', 'PCTime']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])             :  2 | ['Latitude', 'Longitude']\n",
      "\t\t('float', [])                : 30 | ['MEActFOCons', 'DGActFOCons', 'BlrActFOCons', 'DGActMGOCons', 'MEAccFOCons', ...]\n",
      "\t\t('int', [])                  :  5 | ['LogIndex', 'MERpm', 'METorque', 'MEShaftPow', 'WindDir']\n",
      "\t\t('int', ['bool'])            :  1 | ['FCMFODensity']\n",
      "\t\t('int', ['datetime_as_int']) :  4 | ['PCDate', 'PCDate.day', 'PCDate.dayofweek', 'PCTime']\n",
      "\t3.5s = Fit runtime\n",
      "\t40 features in original data used to generate 42 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 67.87 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.6s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2397.00s of the 3596.39s of remaining time.\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] 系统找不到指定的文件。\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\t0.3311\t = Validation score   (r2)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t16.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2377.14s of the 3576.53s of remaining time.\n",
      "\t0.3311\t = Validation score   (r2)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t17.62s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2358.95s of the 3558.35s of remaining time.\n",
      "2025-03-26 10:55:40,308\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.8.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.07%)\n",
      "\t0.7135\t = Validation score   (r2)\n",
      "\t175.76s\t = Training   runtime\n",
      "\t340.35s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2116.62s of the 3316.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.27%)\n",
      "\t0.943\t = Validation score   (r2)\n",
      "\t153.41s\t = Training   runtime\n",
      "\t45.28s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1938.29s of the 3137.69s of remaining time.\n",
      "\t0.9104\t = Validation score   (r2)\n",
      "\t212.42s\t = Training   runtime\n",
      "\t5.39s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1719.81s of the 2919.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.33%)\n",
      "\t0.9788\t = Validation score   (r2)\n",
      "\t1377.44s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 340.17s of the 1539.57s of remaining time.\n",
      "\t0.7596\t = Validation score   (r2)\n",
      "\t33.87s\t = Training   runtime\n",
      "\t6.56s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 298.81s of the 1498.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.73%)\n",
      "\t0.3217\t = Validation score   (r2)\n",
      "\t205.82s\t = Training   runtime\n",
      "\t2.51s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 90.31s of the 1289.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.86%)\n",
      "\t0.9732\t = Validation score   (r2)\n",
      "\t73.49s\t = Training   runtime\n",
      "\t1.84s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 14.17s of the 1213.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.00%)\n",
      "\t0.3825\t = Validation score   (r2)\n",
      "\t13.09s\t = Training   runtime\n",
      "\t1.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1197.77s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.636, 'XGBoost_BAG_L1': 0.364}\n",
      "\t0.9816\t = Validation score   (r2)\n",
      "\t1.78s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 9 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1195.91s of the 1195.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.38%)\n",
      "\t0.8822\t = Validation score   (r2)\n",
      "\t246.85s\t = Training   runtime\n",
      "\t624.0s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 874.67s of the 874.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.40%)\n",
      "\t0.9476\t = Validation score   (r2)\n",
      "\t205.14s\t = Training   runtime\n",
      "\t35.08s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 634.22s of the 634.17s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 245 due to low time. Expected time usage reduced from 773.4s -> 633.8s...\n",
      "\t0.9786\t = Validation score   (r2)\n",
      "\t244.62s\t = Training   runtime\n",
      "\t6.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 382.71s of the 382.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.46%)\n",
      "\t0.9705\t = Validation score   (r2)\n",
      "\t307.04s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 73.21s of the 73.16s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 187 due to low time. Expected time usage reduced from 116.2s -> 72.6s...\n",
      "\t0.9812\t = Validation score   (r2)\n",
      "\t29.99s\t = Training   runtime\n",
      "\t4.46s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 38.04s of the 37.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.17%)\n",
      "\t0.7479\t = Validation score   (r2)\n",
      "\t28.46s\t = Training   runtime\n",
      "\t2.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 6.64s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.333, 'ExtraTreesMSE_BAG_L2': 0.292, 'XGBoost_BAG_L1': 0.167, 'CatBoost_BAG_L2': 0.125, 'RandomForestMSE_BAG_L2': 0.042, 'NeuralNetFastAI_BAG_L2': 0.042}\n",
      "\t0.9831\t = Validation score   (r2)\n",
      "\t2.78s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3596.24s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 69.9 rows/s (28064 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"C:\\code\\EL\\output\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\code\\\\EL\\\\output'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label,eval_metric=metric, path=save_path).fit(train_data, time_limit=time_limit,auto_stack=True)\n",
    "predictor.path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
